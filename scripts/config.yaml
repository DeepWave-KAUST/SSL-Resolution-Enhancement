# Training file folder
dir_train: ../dataset/train/
data_size: 128    # Train samples size

# Time interval of training data
dt: !!float 1e-3

# Frequency cutoff setting
pad: 30
# Warmup phase
cutfreq_warmup: [20, 40]
# IDR phase
cutfreq_idr: [20, 40]

# Training mode
train_mode: SSL   # option: SSL (self-supervised) and SL (supervised)

# Training setting
in_channels: 1
out_channels: 1
total_epoch: 200
warmup_epoch: 20
batch_size: 64
num_workers: 1
lr: !!float 2e-4
loss_type: l1         # option: l1 and l2
optimizer: AdamW      # option: AdamW and Adam
wd: !!float 1e-4
schedule: multistep   # option: cosine and multistep
milestones: [20, 40, 60, 120]
gamma: 0.8
print_freq: 100       # iterations
save_state_freq: 5    # epoch
use_freqloss: True    # whether use focal frequency loss
use_spaloss: True     # whether use sparsity-promotion loss
epsilon1: 10          # hyperparameters to adjust the weight of focal frequency loss
epsilon2: 0.5         # hyperparameters to adjust the weight of sparsity-promotion loss

# Testing file folder
dir_test: ../dataset/test/

# Test setting
cutfreq_test: 10   # If data is synthetic data, we need define
cp_list: [50, 100, 150]  # select trained model in which epoch

